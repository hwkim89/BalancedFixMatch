{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract mean score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isdir('./results/extracted'):\n",
    "#     os.mkdir('./results/extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p = re.compile('0[.]\\d{4}\\s\\D{2}0[.]\\d{2}\\D') #[0.숫자4개 +띄어쓰기 + 문자 2개 0.숫자 2개 + 문자 1개\n",
    "# data_paths = glob.glob('/home/aiffel0042/github_project/AVIDNet/results/*.txt')\n",
    "# data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ori_data_path, data_path in zip(ori_data_paths, data_paths): # 데이터 경로에서 txt파일을 하나씩 불러온다.\n",
    "#     with open(ori_data_path,'r') as f: \n",
    "#         all_data = f.read() # 전체 txt line을 읽어온다.\n",
    "#         all_data = all_data.split('\\n') # 띄어쓰기 기준으로 나눔\n",
    "#         metric_line = all_data[-6:-2] # hard coding.. 맨 뒤 mean result 부분\n",
    "#         extract = p.findall(str(metric_line))# 정규표현식에 맞는것만 뽑아내서 extract에 저장\n",
    "#     with open(data_path,'a') as f:\n",
    "#         for extract_line in extract:\n",
    "#             f.write(str(extract_line)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract mean best scores among all random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = './results/lb25_mu1'\n",
    "# input_dir = './results/lb50_mu1\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.01'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.005'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.004'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.003'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.002'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.001'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0009'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0008'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0007'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0006'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0005'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0001'\n",
    "out_dir = './results/extracted_for_best'\n",
    "# out_fname = 'lb25-mu1-b8,r0,1,2,3.csv'\n",
    "# out_fname = 'lb50-mu1-b8,r0,1,2,3.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.01.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.005.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.004.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.003.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.002.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.001.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0009.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0008.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0007.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0006.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0005.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0001.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './results/lr_with_warmup/lr0.01'\n",
    "# input_dir = './results/lr_with_warmup/lr0.009'\n",
    "# input_dir = './results/lr_with_warmup/lr0.008'\n",
    "# input_dir = './results/lr_with_warmup/lr0.007'\n",
    "# input_dir = './results/lr_with_warmup/lr0.006'\n",
    "# input_dir = './results/lr_with_warmup/lr0.005'\n",
    "# input_dir = './results/lr_with_warmup/lr0.004'\n",
    "# input_dir = './results/lr_with_warmup/lr0.003'\n",
    "# input_dir = './results/lr_with_warmup/lr0.002'\n",
    "# input_dir = './results/lr_with_warmup/lr0.001'\n",
    "out_dir = './results/extracted_for_best'\n",
    "out_fname = 'lr_with_warmup-lr0.01.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.009.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.008.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.007.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.006.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.005.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.004.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.003.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.002.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.001.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = './results/fixaugs'\n",
    "# out_dir = './results/extracted_for_best'\n",
    "# out_fname = 'fixaugs.csv'\n",
    "# if not os.path.isdir(out_dir):\n",
    "#     os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = './results/aug_test_for_nl25'\n",
    "# input_dir = './results/aug_test_for_nl50'\n",
    "# input_dir = './results/aug_test_for_nl100'\n",
    "# input_dir = './results/aug_test_for_nl150'\n",
    "# input_dir = './results/aug_test_for_nl200'\n",
    "# input_dir = './results/aug_test_for_nl300'\n",
    "# input_dir = './results/aug_test_for_nl25_accumulated'\n",
    "# input_dir = './results/aug_test_for_nl50_accumulated'\n",
    "# input_dir = './results/aug_test_for_nl100_accumulated'\n",
    "# input_dir = './results/aug_test_for_nl100_accumulated_e40'\n",
    "input_dir = './results/nl50_aug_result'\n",
    "out_dir = './results/extracted_for_best'\n",
    "# out_fname = 'aug_test_for_nl25.csv'\n",
    "# out_fname = 'aug_test_for_nl50.csv'\n",
    "# out_fname = 'aug_test_for_nl100.csv'\n",
    "# out_fname = 'aug_test_for_nl150.csv'\n",
    "# out_fname = 'aug_test_for_nl200.csv'\n",
    "# out_fname = 'aug_test_for_nl300.csv'\n",
    "# out_fname = 'aug_test_for_nl25_accumulated.csv'\n",
    "# out_fname = 'aug_test_for_nl50_accumulated.csv'\n",
    "# out_fname = 'aug_test_for_nl100_accumulated.csv'\n",
    "# out_fname = 'aug_test_for_nl100_accumulated_e40.csv'\n",
    "out_fname = 'nl50_aug_result.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = './results/aug_test_for_fixmatch_nl50'\n",
    "# input_dir = './results/aug_test_for_fixmatch_nl100'\n",
    "# input_dir = './results/aug_test_for_fixmatch_nl150'\n",
    "# input_dir = './results/aug_test_for_fixmatch_with_focal_loss_nl100/gamma_0.5'\n",
    "input_dir = './results/aug_test_for_fixmatch_with_focal_loss_nl100/gamma_0.8'\n",
    "# input_dir = './results/aug_test_for_fixmatch_with_focal_loss_nl100/gamma_1.0'\n",
    "# input_dir = './results/aug_test_for_fixmatch_with_focal_loss_nl100/gamma_1.2'\n",
    "# input_dir = './results/aug_test_for_fixmatch_with_focal_loss_nl100/gamma_1.5'\n",
    "# input_dir = './results/aug_test_for_fixmatch_with_focal_loss_nl100/gamma_2.0'\n",
    "out_dir = './results/extracted_for_best'\n",
    "# out_fname = 'aug_test_for_fixmatch_nl50.csv'\n",
    "# out_fname = 'aug_test_for_fixmatch_nl100.csv'\n",
    "# out_fname = 'aug_test_for_fixmatch_nl150.csv'\n",
    "# out_fname = 'aug_test_for_fixmatch_with_focal_loss_nl100_gamma0.5.csv'\n",
    "out_fname = 'aug_test_for_fixmatch_with_focal_loss_nl100_gamma0.8.csv'\n",
    "# out_fname = 'aug_test_for_fixmatch_with_focal_loss_nl100_gamma1.0.csv'\n",
    "# out_fname = 'aug_test_for_fixmatch_with_focal_loss_nl100_gamma1.2.csv'\n",
    "# out_fname = 'aug_test_for_fixmatch_with_focal_loss_nl100_gamma1.5.csv'\n",
    "# out_fname = 'aug_test_for_fixmatch_with_focal_loss_nl100_gamma2.0.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './results/randaug_tests/k3'\n",
    "input_dir = './results/randaug_tests/k5'\n",
    "# input_dir = './results/randaug_tests/k5-fg2'\n",
    "out_dir = './results/extracted_for_best'\n",
    "out_fname = 'randaug_tests.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_data_paths = glob.glob(f'{input_dir}/*.txt')\n",
    "# # fix_cols = ['th0.95-lb1.0', 'th0.95-lb0.75', 'th0.95-lb0.5',\n",
    "# #             'th0.98-lb1.0', 'th0.98-lb0.75', 'th0.98-lb0.5']\n",
    "# # fix_cols = ['aug1-th0.95-lb1.0', 'aug2-th0.95-lb1.0', 'aug3-th0.95-lb1.0']\n",
    "# # fix_cols = ['aug1-th0.95-lb1.0', 'aug2-th0.95-lb1.0', 'aug3-th0.95-lb1.0']\n",
    "# # base_cols = [f'bf{i}' for i in range(21)]\n",
    "# # base_cols = ['bf0', 'bf9', 'bf9,16', 'bf16,9', 'bf16,9,3'] # nl25\n",
    "# # base_cols = ['bf0', 'bf50:13', 'bf50:13,9', 'bf50:9,13', 'bf50:13,9,7'] # nl50\n",
    "# # base_cols = ['bf0', 'bf100:9', 'bf14', 'bf100:9,14', 'bf100:14,9', 'bf3', 'bf100:9,14,3'] # nl100\n",
    "# # base_cols = ['bf9,14', 'bf14,9', 'bf9,14,3', \"bf9,3,14\", \"bf14,9,3\", \"bf14,3,9\", \"bf3,9,14\", \"bf3,14,9\"] # nl100_e40\n",
    "# # base_cols = [\"bf13,9\", \"bf9,13\", \"bf13,9,8\", \"bf13,8,9\", \"bf9,13,8\", \"bf9,8,13\", \"bf8,13,9\", \"bf8,9,13\"] # nl100_e40\n",
    "\n",
    "# # Extract paths for each colums such as baseline, fix-th0.95-lb1.0 and so on\n",
    "# data_paths_dict = DefaultOrderedDict(list)\n",
    "# for ori_data_path in ori_data_paths:\n",
    "#     # Exclude the case of the random seed 4 because of performance\n",
    "#     if '-r4-' not in ori_data_path:\n",
    "#         # Baseline\n",
    "#         if 'baseline' in ori_data_path:\n",
    "# #             data_paths_dict['baseline'].append(ori_data_path)\n",
    "#             for base_col in base_cols:\n",
    "#                 if base_col + '.' in ori_data_path:\n",
    "#                     data_paths_dict[f'base-{base_col}'].append(ori_data_path)\n",
    "#                     break\n",
    "                    \n",
    "#         # FixMatch\n",
    "#         else:\n",
    "#             for fix_col in fix_cols:\n",
    "#                 if fix_col in ori_data_path:\n",
    "# #                 if fix_col[:5] in ori_data_path and fix_col[5:] in ori_data_path:\n",
    "#                     data_paths_dict[f'fix-{fix_col}'].append(ori_data_path)\n",
    "# #                     data_paths_dict[f'fix{fix_col}'].append(ori_data_path)\n",
    "#                     break\n",
    "\n",
    "# data_paths_dict['baseline'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_data_paths = glob.glob(f'{input_dir}/*.txt')\n",
    "\n",
    "# Extract paths for each colums such as baseline, fix-th0.95-lb1.0 and so on\n",
    "fm_cols = []\n",
    "data_paths_dict = DefaultOrderedDict(list)\n",
    "for ori_data_path in ori_data_paths:\n",
    "    cond = '-'.join(ori_data_path.split('-')[:5])\n",
    "    cond = cond.split('/')[-1].replace('nl50', 'nl050')\n",
    "    if cond not in fm_cols:\n",
    "        fm_cols.append(cond)\n",
    "    data_paths_dict[cond].append(ori_data_path)\n",
    "    # Baseline\n",
    "#     if 'baseline' in ori_data_path:\n",
    "# #             data_paths_dict['baseline'].append(ori_data_path)\n",
    "#         for base_col in base_cols:\n",
    "#             if base_col + '.' in ori_data_path:\n",
    "#                 data_paths_dict[f'base-{base_col}'].append(ori_data_path)\n",
    "#                 break\n",
    "\n",
    "#     # FixMatch\n",
    "#     else:\n",
    "#         for fix_col in fix_cols:\n",
    "#             if fix_col in ori_data_path:\n",
    "# #                 if fix_col[:5] in ori_data_path and fix_col[5:] in ori_data_path:\n",
    "#                 data_paths_dict[f'fix-{fix_col}'].append(ori_data_path)\n",
    "# #                     data_paths_dict[f'fix{fix_col}'].append(ori_data_path)\n",
    "#                 break\n",
    "\n",
    "fm_cols.sort()\n",
    "len(data_paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc-all</th>\n",
       "      <th>ppv-all</th>\n",
       "      <th>ppv-covid</th>\n",
       "      <th>ppv-pneumonia</th>\n",
       "      <th>ppv-normal</th>\n",
       "      <th>recall-all</th>\n",
       "      <th>recall-covid</th>\n",
       "      <th>recall-pneumonia</th>\n",
       "      <th>recall-normal</th>\n",
       "      <th>f1-all</th>\n",
       "      <th>f1-covid</th>\n",
       "      <th>f1-pneumonia</th>\n",
       "      <th>f1-normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline-nl050-m1-b16</th>\n",
       "      <td>0.8548 (±0.02)</td>\n",
       "      <td>0.8603 (±0.01)</td>\n",
       "      <td>0.9138 (±0.02)</td>\n",
       "      <td>0.8289 (±0.05)</td>\n",
       "      <td>0.8380 (±0.03)</td>\n",
       "      <td>0.8548 (±0.02)</td>\n",
       "      <td>0.8411 (±0.06)</td>\n",
       "      <td>0.8767 (±0.03)</td>\n",
       "      <td>0.8467 (±0.06)</td>\n",
       "      <td>0.8550 (±0.02)</td>\n",
       "      <td>0.8743 (±0.03)</td>\n",
       "      <td>0.8503 (±0.02)</td>\n",
       "      <td>0.8404 (±0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline-nl100-m1-b16</th>\n",
       "      <td>0.8700 (±0.01)</td>\n",
       "      <td>0.8716 (±0.01)</td>\n",
       "      <td>0.8988 (±0.03)</td>\n",
       "      <td>0.8482 (±0.04)</td>\n",
       "      <td>0.8679 (±0.02)</td>\n",
       "      <td>0.8700 (±0.01)</td>\n",
       "      <td>0.8878 (±0.03)</td>\n",
       "      <td>0.8811 (±0.02)</td>\n",
       "      <td>0.8411 (±0.04)</td>\n",
       "      <td>0.8700 (±0.01)</td>\n",
       "      <td>0.8927 (±0.01)</td>\n",
       "      <td>0.8637 (±0.02)</td>\n",
       "      <td>0.8535 (±0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline-nl150-m1-b16</th>\n",
       "      <td>0.8867 (±0.01)</td>\n",
       "      <td>0.8880 (±0.01)</td>\n",
       "      <td>0.9071 (±0.03)</td>\n",
       "      <td>0.8753 (±0.03)</td>\n",
       "      <td>0.8817 (±0.02)</td>\n",
       "      <td>0.8867 (±0.01)</td>\n",
       "      <td>0.9144 (±0.03)</td>\n",
       "      <td>0.8800 (±0.01)</td>\n",
       "      <td>0.8656 (±0.04)</td>\n",
       "      <td>0.8866 (±0.01)</td>\n",
       "      <td>0.9099 (±0.01)</td>\n",
       "      <td>0.8772 (±0.01)</td>\n",
       "      <td>0.8725 (±0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixmatch-nl050-m1-b16</th>\n",
       "      <td>0.8482 (±0.01)</td>\n",
       "      <td>0.8512 (±0.01)</td>\n",
       "      <td>0.8957 (±0.03)</td>\n",
       "      <td>0.8280 (±0.03)</td>\n",
       "      <td>0.8300 (±0.02)</td>\n",
       "      <td>0.8482 (±0.01)</td>\n",
       "      <td>0.8344 (±0.04)</td>\n",
       "      <td>0.8556 (±0.02)</td>\n",
       "      <td>0.8544 (±0.04)</td>\n",
       "      <td>0.8482 (±0.01)</td>\n",
       "      <td>0.8629 (±0.02)</td>\n",
       "      <td>0.8408 (±0.01)</td>\n",
       "      <td>0.8410 (±0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixmatch-nl100-m1-b16</th>\n",
       "      <td>0.8767 (±0.01)</td>\n",
       "      <td>0.8797 (±0.01)</td>\n",
       "      <td>0.9255 (±0.03)</td>\n",
       "      <td>0.8545 (±0.04)</td>\n",
       "      <td>0.8591 (±0.02)</td>\n",
       "      <td>0.8767 (±0.01)</td>\n",
       "      <td>0.8789 (±0.04)</td>\n",
       "      <td>0.8822 (±0.01)</td>\n",
       "      <td>0.8689 (±0.04)</td>\n",
       "      <td>0.8770 (±0.01)</td>\n",
       "      <td>0.9003 (±0.01)</td>\n",
       "      <td>0.8673 (±0.02)</td>\n",
       "      <td>0.8634 (±0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixmatch-nl150-m1-b16</th>\n",
       "      <td>0.8915 (±0.01)</td>\n",
       "      <td>0.8951 (±0.01)</td>\n",
       "      <td>0.9428 (±0.03)</td>\n",
       "      <td>0.8907 (±0.03)</td>\n",
       "      <td>0.8518 (±0.02)</td>\n",
       "      <td>0.8915 (±0.01)</td>\n",
       "      <td>0.8778 (±0.03)</td>\n",
       "      <td>0.8744 (±0.03)</td>\n",
       "      <td>0.9222 (±0.02)</td>\n",
       "      <td>0.8917 (±0.01)</td>\n",
       "      <td>0.9080 (±0.01)</td>\n",
       "      <td>0.8818 (±0.01)</td>\n",
       "      <td>0.8853 (±0.01)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              acc-all         ppv-all       ppv-covid  \\\n",
       "baseline-nl050-m1-b16  0.8548 (±0.02)  0.8603 (±0.01)  0.9138 (±0.02)   \n",
       "baseline-nl100-m1-b16  0.8700 (±0.01)  0.8716 (±0.01)  0.8988 (±0.03)   \n",
       "baseline-nl150-m1-b16  0.8867 (±0.01)  0.8880 (±0.01)  0.9071 (±0.03)   \n",
       "fixmatch-nl050-m1-b16  0.8482 (±0.01)  0.8512 (±0.01)  0.8957 (±0.03)   \n",
       "fixmatch-nl100-m1-b16  0.8767 (±0.01)  0.8797 (±0.01)  0.9255 (±0.03)   \n",
       "fixmatch-nl150-m1-b16  0.8915 (±0.01)  0.8951 (±0.01)  0.9428 (±0.03)   \n",
       "\n",
       "                        ppv-pneumonia      ppv-normal      recall-all  \\\n",
       "baseline-nl050-m1-b16  0.8289 (±0.05)  0.8380 (±0.03)  0.8548 (±0.02)   \n",
       "baseline-nl100-m1-b16  0.8482 (±0.04)  0.8679 (±0.02)  0.8700 (±0.01)   \n",
       "baseline-nl150-m1-b16  0.8753 (±0.03)  0.8817 (±0.02)  0.8867 (±0.01)   \n",
       "fixmatch-nl050-m1-b16  0.8280 (±0.03)  0.8300 (±0.02)  0.8482 (±0.01)   \n",
       "fixmatch-nl100-m1-b16  0.8545 (±0.04)  0.8591 (±0.02)  0.8767 (±0.01)   \n",
       "fixmatch-nl150-m1-b16  0.8907 (±0.03)  0.8518 (±0.02)  0.8915 (±0.01)   \n",
       "\n",
       "                         recall-covid recall-pneumonia   recall-normal  \\\n",
       "baseline-nl050-m1-b16  0.8411 (±0.06)   0.8767 (±0.03)  0.8467 (±0.06)   \n",
       "baseline-nl100-m1-b16  0.8878 (±0.03)   0.8811 (±0.02)  0.8411 (±0.04)   \n",
       "baseline-nl150-m1-b16  0.9144 (±0.03)   0.8800 (±0.01)  0.8656 (±0.04)   \n",
       "fixmatch-nl050-m1-b16  0.8344 (±0.04)   0.8556 (±0.02)  0.8544 (±0.04)   \n",
       "fixmatch-nl100-m1-b16  0.8789 (±0.04)   0.8822 (±0.01)  0.8689 (±0.04)   \n",
       "fixmatch-nl150-m1-b16  0.8778 (±0.03)   0.8744 (±0.03)  0.9222 (±0.02)   \n",
       "\n",
       "                               f1-all        f1-covid    f1-pneumonia  \\\n",
       "baseline-nl050-m1-b16  0.8550 (±0.02)  0.8743 (±0.03)  0.8503 (±0.02)   \n",
       "baseline-nl100-m1-b16  0.8700 (±0.01)  0.8927 (±0.01)  0.8637 (±0.02)   \n",
       "baseline-nl150-m1-b16  0.8866 (±0.01)  0.9099 (±0.01)  0.8772 (±0.01)   \n",
       "fixmatch-nl050-m1-b16  0.8482 (±0.01)  0.8629 (±0.02)  0.8408 (±0.01)   \n",
       "fixmatch-nl100-m1-b16  0.8770 (±0.01)  0.9003 (±0.01)  0.8673 (±0.02)   \n",
       "fixmatch-nl150-m1-b16  0.8917 (±0.01)  0.9080 (±0.01)  0.8818 (±0.01)   \n",
       "\n",
       "                            f1-normal  \n",
       "baseline-nl050-m1-b16  0.8404 (±0.02)  \n",
       "baseline-nl100-m1-b16  0.8535 (±0.02)  \n",
       "baseline-nl150-m1-b16  0.8725 (±0.01)  \n",
       "fixmatch-nl050-m1-b16  0.8410 (±0.01)  \n",
       "fixmatch-nl100-m1-b16  0.8634 (±0.02)  \n",
       "fixmatch-nl150-m1-b16  0.8853 (±0.01)  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile('1[.]\\d{4}|0[.]\\d{4}') #[0.숫자4개]\n",
    "\n",
    "cols = ('acc-all', 'ppv-all', 'ppv-covid', 'ppv-pneumonia', 'ppv-normal',\n",
    "        'recall-all', 'recall-covid', 'recall-pneumonia', 'recall-normal',\n",
    "        'f1-all', 'f1-covid', 'f1-pneumonia', 'f1-normal')\n",
    "metrics_dfs = {}\n",
    "for col, data_paths in data_paths_dict.items(): # 데이터 경로에서 txt파일을 하나씩 불러온다.\n",
    "    metrics_dfs[col] = pd.DataFrame([], columns=cols)\n",
    "    for ori_data_path in data_paths:\n",
    "        with open(ori_data_path, 'r') as f: \n",
    "            all_data = f.read() # 전체 txt line을 읽어온다.\n",
    "            all_data = all_data.split('\\n') # 띄어쓰기 기준으로 나눔\n",
    "            if 'baseline' in ori_data_path:\n",
    "#                 candidates = ((327, 332), (662, 667), (997, 1002),\n",
    "#                               (1332, 1337), (1667, 1672))\n",
    "                candidates = ((327, 332), (662, 667), (997, 1002))\n",
    "#                 candidates = ((647, 652), (1302, 1307), (1957, 1962))\n",
    "            else:\n",
    "#                 candidates = ((347, 352), (702, 707), (1057, 1062),\n",
    "#                               (1412, 1417), (1767, 1772))\n",
    "                candidates = ((347, 352), (702, 707), (1057, 1062))\n",
    "            metrics = []\n",
    "            for s_idx, e_idx in candidates:\n",
    "                metric_line = all_data[s_idx:e_idx] # hard coding.. best result 부분\n",
    "                metrics.append(list(map(float, p.findall(str(metric_line)))))# 정규표현식에 맞는것만 뽑기\n",
    "\n",
    "            metrics_dfs[col] = pd.concat((metrics_dfs[col],\n",
    "                                         pd.DataFrame(metrics, columns=cols))).reset_index(drop=True)\n",
    "\n",
    "# fm_cols = ['baseline'] + [f'fix-{c}' for c in fix_cols]\n",
    "# fm_cols = ['baseline'] + [f'fix{c}' for c in fix_cols]\n",
    "# fm_cols = [f'base-{c}' for c in base_cols]\n",
    "final_metrics_df = pd.DataFrame([], columns=cols)\n",
    "for fm_col in fm_cols:\n",
    "    final_metrics = []\n",
    "    for col in cols:\n",
    "        best_metrics = metrics_dfs[fm_col][col].to_numpy()\n",
    "        mean, std = best_metrics.mean(), best_metrics.std()\n",
    "        final_metrics.append(f'{mean:.4f} (±{std:.2f})')\n",
    "        \n",
    "    final_metrics_df = final_metrics_df.append(pd.DataFrame([final_metrics], columns=cols, index=(fm_col,)))\n",
    "\n",
    "final_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 14, 3), (9, 3, 14), (14, 9, 3), (14, 3, 9), (3, 9, 14), (3, 14, 9)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from itertools import permutations\n",
    "# list(permutations([9, 14, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics_df.to_csv(f'{out_dir}/{out_fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooks/anaconda3/envs/avidnet/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, Callable\n",
    "\n",
    "class DefaultOrderedDict(OrderedDict):\n",
    "    # Source: http://stackoverflow.com/a/6190500/562769\n",
    "    def __init__(self, default_factory=None, *a, **kw):\n",
    "        if (default_factory is not None and\n",
    "           not isinstance(default_factory, Callable)):\n",
    "            raise TypeError('first argument must be callable')\n",
    "        OrderedDict.__init__(self, *a, **kw)\n",
    "        self.default_factory = default_factory\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        try:\n",
    "            return OrderedDict.__getitem__(self, key)\n",
    "        except KeyError:\n",
    "            return self.__missing__(key)\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        if self.default_factory is None:\n",
    "            raise KeyError(key)\n",
    "        self[key] = value = self.default_factory()\n",
    "        return value\n",
    "\n",
    "    def __reduce__(self):\n",
    "        if self.default_factory is None:\n",
    "            args = tuple()\n",
    "        else:\n",
    "            args = self.default_factory,\n",
    "        return type(self), args, None, None, self.items()\n",
    "\n",
    "    def copy(self):\n",
    "        return self.__copy__()\n",
    "\n",
    "    def __copy__(self):\n",
    "        return type(self)(self.default_factory, self)\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        import copy\n",
    "        return type(self)(self.default_factory,\n",
    "                          copy.deepcopy(self.items()))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrderedDefaultDict(%s, %s)' % (self.default_factory,\n",
    "                                               OrderedDict.__repr__(self))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
