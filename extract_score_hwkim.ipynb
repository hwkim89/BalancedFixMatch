{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract mean score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isdir('./results/extracted'):\n",
    "#     os.mkdir('./results/extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p = re.compile('0[.]\\d{4}\\s\\D{2}0[.]\\d{2}\\D') #[0.숫자4개 +띄어쓰기 + 문자 2개 0.숫자 2개 + 문자 1개\n",
    "# data_paths = glob.glob('/home/aiffel0042/github_project/AVIDNet/results/*.txt')\n",
    "# data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ori_data_path, data_path in zip(ori_data_paths, data_paths): # 데이터 경로에서 txt파일을 하나씩 불러온다.\n",
    "#     with open(ori_data_path,'r') as f: \n",
    "#         all_data = f.read() # 전체 txt line을 읽어온다.\n",
    "#         all_data = all_data.split('\\n') # 띄어쓰기 기준으로 나눔\n",
    "#         metric_line = all_data[-6:-2] # hard coding.. 맨 뒤 mean result 부분\n",
    "#         extract = p.findall(str(metric_line))# 정규표현식에 맞는것만 뽑아내서 extract에 저장\n",
    "#     with open(data_path,'a') as f:\n",
    "#         for extract_line in extract:\n",
    "#             f.write(str(extract_line)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract mean best scores among all random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = './results/lb25_mu1'\n",
    "# input_dir = './results/lb50_mu1\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.01'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.005'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.004'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.003'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.002'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.001'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0009'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0008'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0007'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0006'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0005'\n",
    "# input_dir = './results/nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0001'\n",
    "out_dir = './results/extracted_for_best'\n",
    "# out_fname = 'lb25-mu1-b8,r0,1,2,3.csv'\n",
    "# out_fname = 'lb50-mu1-b8,r0,1,2,3.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.01.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.005.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.004.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.003.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.002.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.001.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0009.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0008.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0007.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0006.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0005.csv'\n",
    "# out_fname = 'nl25-m1-b16-r0,1,2-th0.95-lb1.0-sc:step-lr0.0001.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './results/lr_with_warmup/lr0.01'\n",
    "# input_dir = './results/lr_with_warmup/lr0.009'\n",
    "# input_dir = './results/lr_with_warmup/lr0.008'\n",
    "# input_dir = './results/lr_with_warmup/lr0.007'\n",
    "# input_dir = './results/lr_with_warmup/lr0.006'\n",
    "# input_dir = './results/lr_with_warmup/lr0.005'\n",
    "# input_dir = './results/lr_with_warmup/lr0.004'\n",
    "# input_dir = './results/lr_with_warmup/lr0.003'\n",
    "# input_dir = './results/lr_with_warmup/lr0.002'\n",
    "# input_dir = './results/lr_with_warmup/lr0.001'\n",
    "out_dir = './results/extracted_for_best'\n",
    "out_fname = 'lr_with_warmup-lr0.01.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.009.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.008.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.007.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.006.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.005.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.004.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.003.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.002.csv'\n",
    "# out_fname = 'lr_with_warmup-lr0.001.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = './results/fixaugs'\n",
    "# out_dir = './results/extracted_for_best'\n",
    "# out_fname = 'fixaugs.csv'\n",
    "# if not os.path.isdir(out_dir):\n",
    "#     os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = './results/aug_test_for_nl25'\n",
    "# input_dir = './results/aug_test_for_nl50'\n",
    "# input_dir = './results/aug_test_for_nl100'\n",
    "# input_dir = './results/aug_test_for_nl150'\n",
    "# input_dir = './results/aug_test_for_nl200'\n",
    "# input_dir = './results/aug_test_for_nl300'\n",
    "# input_dir = './results/aug_test_for_nl25_accumulated'\n",
    "input_dir = './results/aug_test_for_nl50_accumulated'\n",
    "# input_dir = './results/aug_test_for_nl100_accumulated'\n",
    "out_dir = './results/extracted_for_best'\n",
    "# out_fname = 'aug_test_for_nl25.csv'\n",
    "# out_fname = 'aug_test_for_nl50.csv'\n",
    "# out_fname = 'aug_test_for_nl100.csv'\n",
    "# out_fname = 'aug_test_for_nl150.csv'\n",
    "# out_fname = 'aug_test_for_nl200.csv'\n",
    "# out_fname = 'aug_test_for_nl300.csv'\n",
    "# out_fname = 'aug_test_for_nl25_accumulated.csv'\n",
    "out_fname = 'aug_test_for_nl50_accumulated.csv'\n",
    "# out_fname = 'aug_test_for_nl100_accumulated.csv'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_data_paths = glob.glob(f'{input_dir}/*.txt')\n",
    "# fix_cols = ['th0.95-lb1.0', 'th0.95-lb0.75', 'th0.95-lb0.5',\n",
    "#             'th0.98-lb1.0', 'th0.98-lb0.75', 'th0.98-lb0.5']\n",
    "# fix_cols = ['aug1-th0.95-lb1.0', 'aug2-th0.95-lb1.0', 'aug3-th0.95-lb1.0']\n",
    "# base_cols = [f'bf{i}' for i in range(21)]\n",
    "# base_cols = ['bf0', 'bf9', 'bf9,16', 'bf16,9', 'bf16,9,3'] # nl25\n",
    "base_cols = ['bf0', 'bf50:13', 'bf50:13,9', 'bf50:9,13', 'bf50:13,9,7'] # nl50\n",
    "# base_cols = ['bf0', 'bf100:9', 'bf14', 'bf100:9,14', 'bf100:14,9', 'bf3', 'bf100:9,14,3'] # nl100\n",
    "\n",
    "# Extract paths for each colums such as baseline, fix-th0.95-lb1.0 and so on\n",
    "data_paths_dict = DefaultOrderedDict(list)\n",
    "for ori_data_path in ori_data_paths:\n",
    "    # Exclude the case of the random seed 4 because of performance\n",
    "    if '-r4-' not in ori_data_path:\n",
    "        # Baseline\n",
    "        if 'baseline' in ori_data_path:\n",
    "#             data_paths_dict['baseline'].append(ori_data_path)\n",
    "            for base_col in base_cols:\n",
    "                if base_col + '.' in ori_data_path:\n",
    "                    data_paths_dict[f'base-{base_col}'].append(ori_data_path)\n",
    "                    break\n",
    "                    \n",
    "        # FixMatch\n",
    "        else:\n",
    "            for fix_col in fix_cols:\n",
    "                if fix_col in ori_data_path:\n",
    "#                 if fix_col[:5] in ori_data_path and fix_col[5:] in ori_data_path:\n",
    "                    data_paths_dict[f'fix-{fix_col}'].append(ori_data_path)\n",
    "#                     data_paths_dict[f'fix{fix_col}'].append(ori_data_path)\n",
    "                    break\n",
    "\n",
    "data_paths_dict['baseline'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc-all</th>\n",
       "      <th>ppv-all</th>\n",
       "      <th>ppv-covid</th>\n",
       "      <th>ppv-pneumonia</th>\n",
       "      <th>ppv-normal</th>\n",
       "      <th>recall-all</th>\n",
       "      <th>recall-covid</th>\n",
       "      <th>recall-pneumonia</th>\n",
       "      <th>recall-normal</th>\n",
       "      <th>f1-all</th>\n",
       "      <th>f1-covid</th>\n",
       "      <th>f1-pneumonia</th>\n",
       "      <th>f1-normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base-bf0</th>\n",
       "      <td>0.8204 (±0.01)</td>\n",
       "      <td>0.8281 (±0.01)</td>\n",
       "      <td>0.9102 (±0.02)</td>\n",
       "      <td>0.7655 (±0.03)</td>\n",
       "      <td>0.8087 (±0.03)</td>\n",
       "      <td>0.8204 (±0.01)</td>\n",
       "      <td>0.7900 (±0.04)</td>\n",
       "      <td>0.8756 (±0.03)</td>\n",
       "      <td>0.7956 (±0.03)</td>\n",
       "      <td>0.8208 (±0.01)</td>\n",
       "      <td>0.8449 (±0.02)</td>\n",
       "      <td>0.8162 (±0.02)</td>\n",
       "      <td>0.8012 (±0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base-bf50:13</th>\n",
       "      <td>0.8407 (±0.01)</td>\n",
       "      <td>0.8476 (±0.01)</td>\n",
       "      <td>0.9239 (±0.03)</td>\n",
       "      <td>0.8196 (±0.04)</td>\n",
       "      <td>0.7994 (±0.04)</td>\n",
       "      <td>0.8407 (±0.01)</td>\n",
       "      <td>0.8078 (±0.03)</td>\n",
       "      <td>0.8656 (±0.02)</td>\n",
       "      <td>0.8489 (±0.04)</td>\n",
       "      <td>0.8415 (±0.01)</td>\n",
       "      <td>0.8612 (±0.02)</td>\n",
       "      <td>0.8411 (±0.02)</td>\n",
       "      <td>0.8222 (±0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base-bf50:13,9</th>\n",
       "      <td>0.8400 (±0.01)</td>\n",
       "      <td>0.8475 (±0.01)</td>\n",
       "      <td>0.9264 (±0.02)</td>\n",
       "      <td>0.7986 (±0.03)</td>\n",
       "      <td>0.8174 (±0.03)</td>\n",
       "      <td>0.8400 (±0.01)</td>\n",
       "      <td>0.8089 (±0.04)</td>\n",
       "      <td>0.8911 (±0.03)</td>\n",
       "      <td>0.8200 (±0.06)</td>\n",
       "      <td>0.8402 (±0.01)</td>\n",
       "      <td>0.8626 (±0.02)</td>\n",
       "      <td>0.8413 (±0.02)</td>\n",
       "      <td>0.8166 (±0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base-bf50:9,13</th>\n",
       "      <td>0.8396 (±0.02)</td>\n",
       "      <td>0.8459 (±0.01)</td>\n",
       "      <td>0.9101 (±0.03)</td>\n",
       "      <td>0.8020 (±0.04)</td>\n",
       "      <td>0.8258 (±0.01)</td>\n",
       "      <td>0.8396 (±0.02)</td>\n",
       "      <td>0.8044 (±0.06)</td>\n",
       "      <td>0.8789 (±0.04)</td>\n",
       "      <td>0.8356 (±0.02)</td>\n",
       "      <td>0.8397 (±0.02)</td>\n",
       "      <td>0.8519 (±0.03)</td>\n",
       "      <td>0.8369 (±0.02)</td>\n",
       "      <td>0.8304 (±0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base-bf50:13,9,7</th>\n",
       "      <td>0.8322 (±0.01)</td>\n",
       "      <td>0.8407 (±0.01)</td>\n",
       "      <td>0.9222 (±0.03)</td>\n",
       "      <td>0.7811 (±0.03)</td>\n",
       "      <td>0.8187 (±0.02)</td>\n",
       "      <td>0.8322 (±0.01)</td>\n",
       "      <td>0.7900 (±0.05)</td>\n",
       "      <td>0.8911 (±0.03)</td>\n",
       "      <td>0.8156 (±0.02)</td>\n",
       "      <td>0.8325 (±0.01)</td>\n",
       "      <td>0.8493 (±0.02)</td>\n",
       "      <td>0.8314 (±0.01)</td>\n",
       "      <td>0.8168 (±0.01)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc-all         ppv-all       ppv-covid  \\\n",
       "base-bf0          0.8204 (±0.01)  0.8281 (±0.01)  0.9102 (±0.02)   \n",
       "base-bf50:13      0.8407 (±0.01)  0.8476 (±0.01)  0.9239 (±0.03)   \n",
       "base-bf50:13,9    0.8400 (±0.01)  0.8475 (±0.01)  0.9264 (±0.02)   \n",
       "base-bf50:9,13    0.8396 (±0.02)  0.8459 (±0.01)  0.9101 (±0.03)   \n",
       "base-bf50:13,9,7  0.8322 (±0.01)  0.8407 (±0.01)  0.9222 (±0.03)   \n",
       "\n",
       "                   ppv-pneumonia      ppv-normal      recall-all  \\\n",
       "base-bf0          0.7655 (±0.03)  0.8087 (±0.03)  0.8204 (±0.01)   \n",
       "base-bf50:13      0.8196 (±0.04)  0.7994 (±0.04)  0.8407 (±0.01)   \n",
       "base-bf50:13,9    0.7986 (±0.03)  0.8174 (±0.03)  0.8400 (±0.01)   \n",
       "base-bf50:9,13    0.8020 (±0.04)  0.8258 (±0.01)  0.8396 (±0.02)   \n",
       "base-bf50:13,9,7  0.7811 (±0.03)  0.8187 (±0.02)  0.8322 (±0.01)   \n",
       "\n",
       "                    recall-covid recall-pneumonia   recall-normal  \\\n",
       "base-bf0          0.7900 (±0.04)   0.8756 (±0.03)  0.7956 (±0.03)   \n",
       "base-bf50:13      0.8078 (±0.03)   0.8656 (±0.02)  0.8489 (±0.04)   \n",
       "base-bf50:13,9    0.8089 (±0.04)   0.8911 (±0.03)  0.8200 (±0.06)   \n",
       "base-bf50:9,13    0.8044 (±0.06)   0.8789 (±0.04)  0.8356 (±0.02)   \n",
       "base-bf50:13,9,7  0.7900 (±0.05)   0.8911 (±0.03)  0.8156 (±0.02)   \n",
       "\n",
       "                          f1-all        f1-covid    f1-pneumonia  \\\n",
       "base-bf0          0.8208 (±0.01)  0.8449 (±0.02)  0.8162 (±0.02)   \n",
       "base-bf50:13      0.8415 (±0.01)  0.8612 (±0.02)  0.8411 (±0.02)   \n",
       "base-bf50:13,9    0.8402 (±0.01)  0.8626 (±0.02)  0.8413 (±0.02)   \n",
       "base-bf50:9,13    0.8397 (±0.02)  0.8519 (±0.03)  0.8369 (±0.02)   \n",
       "base-bf50:13,9,7  0.8325 (±0.01)  0.8493 (±0.02)  0.8314 (±0.01)   \n",
       "\n",
       "                       f1-normal  \n",
       "base-bf0          0.8012 (±0.02)  \n",
       "base-bf50:13      0.8222 (±0.02)  \n",
       "base-bf50:13,9    0.8166 (±0.02)  \n",
       "base-bf50:9,13    0.8304 (±0.01)  \n",
       "base-bf50:13,9,7  0.8168 (±0.01)  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile('1[.]\\d{4}|0[.]\\d{4}') #[0.숫자4개]\n",
    "\n",
    "cols = ('acc-all', 'ppv-all', 'ppv-covid', 'ppv-pneumonia', 'ppv-normal',\n",
    "        'recall-all', 'recall-covid', 'recall-pneumonia', 'recall-normal',\n",
    "        'f1-all', 'f1-covid', 'f1-pneumonia', 'f1-normal')\n",
    "metrics_dfs = {}\n",
    "for col, data_paths in data_paths_dict.items(): # 데이터 경로에서 txt파일을 하나씩 불러온다.\n",
    "    metrics_dfs[col] = pd.DataFrame([], columns=cols)\n",
    "    for ori_data_path in data_paths:\n",
    "        with open(ori_data_path, 'r') as f: \n",
    "            all_data = f.read() # 전체 txt line을 읽어온다.\n",
    "            all_data = all_data.split('\\n') # 띄어쓰기 기준으로 나눔\n",
    "            if 'baseline' in ori_data_path:\n",
    "#                 candidates = ((327, 332), (662, 667), (997, 1002),\n",
    "#                               (1332, 1337), (1667, 1672))\n",
    "                candidates = ((327, 332), (662, 667), (997, 1002))\n",
    "            else:\n",
    "#                 candidates = ((347, 352), (702, 707), (1057, 1062),\n",
    "#                               (1412, 1417), (1767, 1772))\n",
    "                candidates = ((347, 352), (702, 707), (1057, 1062))\n",
    "            metrics = []\n",
    "            for s_idx, e_idx in candidates:\n",
    "                metric_line = all_data[s_idx:e_idx] # hard coding.. best result 부분\n",
    "                metrics.append(list(map(float, p.findall(str(metric_line)))))# 정규표현식에 맞는것만 뽑기\n",
    "\n",
    "            metrics_dfs[col] = pd.concat((metrics_dfs[col],\n",
    "                                         pd.DataFrame(metrics, columns=cols))).reset_index(drop=True)\n",
    "\n",
    "# fm_cols = ['baseline'] + [f'fix-{c}' for c in fix_cols]\n",
    "# fm_cols = ['baseline'] + [f'fix{c}' for c in fix_cols]\n",
    "fm_cols = [f'base-{c}' for c in base_cols]\n",
    "final_metrics_df = pd.DataFrame([], columns=cols)\n",
    "for fm_col in fm_cols:\n",
    "    final_metrics = []\n",
    "    for col in cols:\n",
    "        best_metrics = metrics_dfs[fm_col][col].to_numpy()\n",
    "        mean, std = best_metrics.mean(), best_metrics.std()\n",
    "        final_metrics.append(f'{mean:.4f} (±{std:.2f})')\n",
    "        \n",
    "    final_metrics_df = final_metrics_df.append(pd.DataFrame([final_metrics], columns=cols, index=(fm_col,)))\n",
    "\n",
    "final_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 14, 3), (9, 3, 14), (14, 9, 3), (14, 3, 9), (3, 9, 14), (3, 14, 9)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from itertools import permutations\n",
    "# list(permutations([9, 14, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics_df.to_csv(f'{out_dir}/{out_fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooks/anaconda3/envs/avidnet/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, Callable\n",
    "\n",
    "class DefaultOrderedDict(OrderedDict):\n",
    "    # Source: http://stackoverflow.com/a/6190500/562769\n",
    "    def __init__(self, default_factory=None, *a, **kw):\n",
    "        if (default_factory is not None and\n",
    "           not isinstance(default_factory, Callable)):\n",
    "            raise TypeError('first argument must be callable')\n",
    "        OrderedDict.__init__(self, *a, **kw)\n",
    "        self.default_factory = default_factory\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        try:\n",
    "            return OrderedDict.__getitem__(self, key)\n",
    "        except KeyError:\n",
    "            return self.__missing__(key)\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        if self.default_factory is None:\n",
    "            raise KeyError(key)\n",
    "        self[key] = value = self.default_factory()\n",
    "        return value\n",
    "\n",
    "    def __reduce__(self):\n",
    "        if self.default_factory is None:\n",
    "            args = tuple()\n",
    "        else:\n",
    "            args = self.default_factory,\n",
    "        return type(self), args, None, None, self.items()\n",
    "\n",
    "    def copy(self):\n",
    "        return self.__copy__()\n",
    "\n",
    "    def __copy__(self):\n",
    "        return type(self)(self.default_factory, self)\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        import copy\n",
    "        return type(self)(self.default_factory,\n",
    "                          copy.deepcopy(self.items()))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrderedDefaultDict(%s, %s)' % (self.default_factory,\n",
    "                                               OrderedDict.__repr__(self))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
